{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130bbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83bb7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Basic DataFrame\n",
    "df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], \n",
    "                  columns=[\"A\", \"B\", \"C\"],\n",
    "                  index=[\"x\", \"Y\", \"Z\", \"BA\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78b78a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Some useful functions about dataframes\n",
    "\n",
    "df.head() # Show the first 5 rows\n",
    "# df.head(2) # first 2 rows\n",
    "# df.tail(2) # last 2 rows\n",
    "# df.columns # Show the column names\n",
    "# df.index # Show the row names\n",
    "# df.info() # Show info such as the columns and their types\n",
    "# statsDf = df.describe() # Means, maxes, stats, etc\n",
    "# display(statsDf)\n",
    "# display(df.head())\n",
    "\n",
    "# # Columns and unique Values\n",
    "# A = df['A']\n",
    "# uVals = A.unique()\n",
    "# display(A)\n",
    "# display(type(A))\n",
    "# display(uVals)\n",
    "\n",
    "df.shape # (rows,cols)\n",
    "df.size # Total Number of elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read from a parquet\n",
    "# results = pd.read_parquet('./data/results.parquet')\n",
    "# results.to_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a175628",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read excel\n",
    "# olympics_data = pd.read_excel('./data/olympics-data.xlsx', sheet_name='results')\n",
    "# olympics_data.to_excel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a4f5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading from a CSV File\n",
    "coffee = pd.read_csv('./warmup-data/coffee.csv')\n",
    "# # coffee.to_parquet(path=\"./check.parquet\") # Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a16f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Monday\n",
       "1        Monday\n",
       "2       Tuesday\n",
       "3       Tuesday\n",
       "4     Wednesday\n",
       "5     Wednesday\n",
       "6      Thursday\n",
       "7      Thursday\n",
       "8        Friday\n",
       "9        Friday\n",
       "10     Saturday\n",
       "11     Saturday\n",
       "12       Sunday\n",
       "13       Sunday\n",
       "Name: Day, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Accessing Data \n",
    "# coffee.sample(3, random_state=2) # Get some random rows (repeatable with random_state)\n",
    "coffee.loc[:, [\"Day\", \"Units Sold\"]] # Loc returns just the rows and cols that you want\n",
    "coffee.iloc[:,1] # Allows you to use integer based indexing \n",
    "coffee.Day # Grab a single column\n",
    "# coffee.index = coffee.Day # Set the index\n",
    "# coffee\n",
    "\n",
    "\n",
    "# Note that for single values you can use iat or at, for slightly better performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2a59d296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setting various bits of data\n",
    "coffee.loc[0,\"Units Sold\"] # has value of 25\n",
    "coffee.loc[0:2,'Units Sold'] = 20 #Now it has a value of 20\n",
    "coffee.loc[0,'Units Sold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd09b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## More Useful functions\n",
    "coffee.sort_values([\"Coffee Type\", \"Units Sold\"], ascending=[False, True])\n",
    "coffee['Coffee Type'].unique()\n",
    "\n",
    "# If you need to loop through\n",
    "# Note that this is not very efficient.  Try to stick to built in pandas methods\n",
    "for idx, row in coffee.iterrows():\n",
    "    print(f\"{idx} {row}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load more Data\n",
    "bios = pd.read_csv('./data/bios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "87d639a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOC</th>\n",
       "      <th>name</th>\n",
       "      <th>born_region</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>born_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>United States</td>\n",
       "      <td>Tommy Burleson</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>223.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>United States</td>\n",
       "      <td>Shaquille O'Neal</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>216.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>United States</td>\n",
       "      <td>David Robinson</td>\n",
       "      <td>Florida</td>\n",
       "      <td>216.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123850</th>\n",
       "      <td>United States</td>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>California</td>\n",
       "      <td>216.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NOC              name     born_region  height_cm  \\\n",
       "5781    United States    Tommy Burleson  North Carolina      223.0   \n",
       "6722    United States  Shaquille O'Neal      New Jersey      216.0   \n",
       "6937    United States    David Robinson         Florida      216.0   \n",
       "123850  United States    Tyson Chandler      California      216.0   \n",
       "\n",
       "       born_country  \n",
       "5781            USA  \n",
       "6722            USA  \n",
       "6937            USA  \n",
       "123850          USA  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filtering Operations\n",
    "rowPts = (bios['height_cm'] > 215) & (bios['born_country']=='USA')\n",
    "cols_to_keep =  [\"NOC\", \"name\", \"born_region\",\"height_cm\",\"born_country\"]\n",
    "filtered_df = bios.loc[rowPts, cols_to_keep]\n",
    "filtered_df = bios[rowPts][cols_to_keep] # this is equivelent to the previos line\n",
    "sorted_filtered_df = filtered_df.sort_values(\"height_cm\", ascending=False)\n",
    "sorted_filtered_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9edac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>name</th>\n",
       "      <th>born_date</th>\n",
       "      <th>born_city</th>\n",
       "      <th>born_region</th>\n",
       "      <th>born_country</th>\n",
       "      <th>NOC</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>died_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2210</td>\n",
       "      <td>Trena King</td>\n",
       "      <td>1958-01-17</td>\n",
       "      <td>Kingwood</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>172.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      athlete_id        name   born_date born_city    born_region  \\\n",
       "2200        2210  Trena King  1958-01-17  Kingwood  West Virginia   \n",
       "\n",
       "     born_country            NOC  height_cm  weight_kg died_date  \n",
       "2200          USA  United States      172.0       68.0       NaN  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filter with string operations\n",
    "name_pts = bios['name'].str.contains(r're[nw]', case=False)\n",
    "country_pts = bios['born_country'].isin(['USA', 'FRA'])\n",
    "notNanPts = ~bios['height_cm'].isna()\n",
    "bios[name_pts & notNanPts & country_pts][cols_to_keep]\n",
    "\n",
    "# Filter using complex Query \n",
    "# Would need to learn this way more...\n",
    "bios.query('name == \"Trena King\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b551df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding / Removing Columns\n",
    "# Add Price Uniformly\n",
    "coffee['Price'] = 4.99 # Set for all rows\n",
    "\n",
    "import numpy as np\n",
    "coffee['new_price'] = np.where(coffee['Coffee Type'] == 'Espresso', 3.99,5.99) #espresso is 399 and all else is 599\n",
    "\n",
    "\n",
    "\n",
    "## Practice with Merging DFS\n",
    "price_df = pd.DataFrame([['Espresso', 3.99], ['Latte',5.99]], columns=['Coffee Type', 'DF Price'])\n",
    "right_df = coffee.merge(price_df, 'right')\n",
    "left_df = coffee.merge(price_df, 'left')\n",
    "coffee = left_df.copy() # This is how you make a deep copy\n",
    "# display(right_df)\n",
    "# display(left_df)\n",
    "\n",
    "## Drop the initial columns\n",
    "coffee = coffee.drop(columns=['Price', 'new_price'])\n",
    "\n",
    "## Perform some simple calculations\n",
    "coffee = coffee.rename(columns={'DF Price':'Price'})\n",
    "coffee['revenue'] = coffee['Units Sold'] * coffee['Price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145500 entries, 0 to 145499\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   born_date               143693 non-null  object        \n",
      " 1   born_datetime           143693 non-null  datetime64[ns]\n",
      " 2   born_year_str           143693 non-null  object        \n",
      " 3   born_year_datetime      143693 non-null  float64       \n",
      " 4   born_year_datetime_str  145500 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "bios_new = bios.copy()\n",
    "# bios_new\n",
    "bios_new['first_name'] = bios_new['name'].str.split(' ').str[0]\n",
    "# bios_new.info()\n",
    "bios_new['born_year_str'] = bios_new['born_date'].str.split('-').str[0]\n",
    "bios_new['born_datetime'] = pd.to_datetime(bios_new['born_date'],format=\"%Y-%m-%d\")\n",
    "bios_new['born_year_datetime'] = bios_new['born_datetime'].dt.year\n",
    "check = bios_new[['born_date', 'born_datetime', 'born_year_str', 'born_year_datetime', 'born_year_datetime_str']]\n",
    "check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c789be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190790378006873"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Complicated Column using apply\n",
    "bios_new['height_category'] = bios_new['height_cm'].apply(lambda x:'tall' if x > 165 else 'shorty')\n",
    "sum(bios_new['height_category'] == 'tall') / bios_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "dee45145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          heavyweight\n",
       "1         middleweight\n",
       "2         middleweight\n",
       "3         middleweight\n",
       "4          heavyweight\n",
       "              ...     \n",
       "145495    middleweight\n",
       "145496    middleweight\n",
       "145497     lightweight\n",
       "145498    middleweight\n",
       "145499     heavyweight\n",
       "Name: weight_category, Length: 145500, dtype: object"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply even more complicated function defined\n",
    "# THis is not as efficient as built ins, but sometimes that is ok\n",
    "def getWeightClass(row):\n",
    "    if row['weight_kg'] < 70 and row['height_category']=='shorty':\n",
    "        return 'lightweight'\n",
    "    elif row['weight_kg'] >= 80 or row['height_category'] == 'tall':\n",
    "        return 'middleweight'\n",
    "    else:\n",
    "        return 'heavyweight'\n",
    "\n",
    "bios_new['weight_category'] = bios_new.apply(getWeightClass, axis=1)\n",
    "bios_new['weight_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feacb06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>name</th>\n",
       "      <th>born_date</th>\n",
       "      <th>born_city</th>\n",
       "      <th>born_region</th>\n",
       "      <th>born_country</th>\n",
       "      <th>NOC</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>died_date</th>\n",
       "      <th>first_name</th>\n",
       "      <th>born_year_str</th>\n",
       "      <th>born_datetime</th>\n",
       "      <th>born_year_datetime</th>\n",
       "      <th>born_year_datetime_str</th>\n",
       "      <th>height_category</th>\n",
       "      <th>weight_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144659</th>\n",
       "      <td>148355</td>\n",
       "      <td>Bruce Mouat</td>\n",
       "      <td>1994-08-27</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994-08-27</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144661</th>\n",
       "      <td>148357</td>\n",
       "      <td>Leonie Gerken Schofield</td>\n",
       "      <td>1998-02-15</td>\n",
       "      <td>Chelmsford</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leonie</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-02-15</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144662</th>\n",
       "      <td>148358</td>\n",
       "      <td>Makayla Gerken Schofield</td>\n",
       "      <td>1999-06-04</td>\n",
       "      <td>Chelmsford</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Makayla</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-06-04</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144663</th>\n",
       "      <td>148359</td>\n",
       "      <td>Ollie Davies</td>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>Guildford</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ollie</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144664</th>\n",
       "      <td>148360</td>\n",
       "      <td>William Feneley</td>\n",
       "      <td>1999-07-13</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>William</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-07-13</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144666</th>\n",
       "      <td>148362</td>\n",
       "      <td>Natasha McKay</td>\n",
       "      <td>1995-01-14</td>\n",
       "      <td>Dundee</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natasha</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-01-14</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144667</th>\n",
       "      <td>148363</td>\n",
       "      <td>Lewis Gibson</td>\n",
       "      <td>1994-05-01</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994-05-01</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144668</th>\n",
       "      <td>148364</td>\n",
       "      <td>Katie Ormerod</td>\n",
       "      <td>1997-08-25</td>\n",
       "      <td>Bradford</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katie</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-08-25</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144669</th>\n",
       "      <td>148365</td>\n",
       "      <td>Huw Nightingale</td>\n",
       "      <td>2001-11-12</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huw</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001-11-12</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144670</th>\n",
       "      <td>148366</td>\n",
       "      <td>Brogan Crowley</td>\n",
       "      <td>1994-07-20</td>\n",
       "      <td>Saddleworth</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brogan</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994-07-20</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144671</th>\n",
       "      <td>148367</td>\n",
       "      <td>Matt Weston</td>\n",
       "      <td>1997-03-02</td>\n",
       "      <td>Redhill</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matt</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-03-02</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144672</th>\n",
       "      <td>148368</td>\n",
       "      <td>Marcus Wyatt</td>\n",
       "      <td>1991-12-14</td>\n",
       "      <td>Honiton</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991-12-14</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144673</th>\n",
       "      <td>148369</td>\n",
       "      <td>Ellia Smeding</td>\n",
       "      <td>1998-03-16</td>\n",
       "      <td>Aylesbury</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellia</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-03-16</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144675</th>\n",
       "      <td>148371</td>\n",
       "      <td>Niall Treacy</td>\n",
       "      <td>2000-07-22</td>\n",
       "      <td>Solihull</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Niall</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07-22</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144760</th>\n",
       "      <td>148461</td>\n",
       "      <td>Elsa Desmond</td>\n",
       "      <td>1997-08-06</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsa</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-08-06</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144811</th>\n",
       "      <td>148512</td>\n",
       "      <td>Benjamin Alexander</td>\n",
       "      <td>1983-05-08</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983-05-08</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144815</th>\n",
       "      <td>148517</td>\n",
       "      <td>Ashley Watson</td>\n",
       "      <td>1993-10-28</td>\n",
       "      <td>Peterborough</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993-10-28</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145005</th>\n",
       "      <td>148716</td>\n",
       "      <td>Peder Kongshaug</td>\n",
       "      <td>2001-08-13</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Norway</td>\n",
       "      <td>184.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peder</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001-08-13</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>tall</td>\n",
       "      <td>middleweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145319</th>\n",
       "      <td>149041</td>\n",
       "      <td>Axel Brown</td>\n",
       "      <td>1992-04-02</td>\n",
       "      <td>Harrogate</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Axel</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992-04-02</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145388</th>\n",
       "      <td>149111</td>\n",
       "      <td>Jean-Luc Baker</td>\n",
       "      <td>1993-10-07</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>England</td>\n",
       "      <td>GBR</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jean-Luc</td>\n",
       "      <td>1993</td>\n",
       "      <td>1993-10-07</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>shorty</td>\n",
       "      <td>heavyweight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        athlete_id                      name   born_date     born_city  \\\n",
       "144659      148355               Bruce Mouat  1994-08-27     Edinburgh   \n",
       "144661      148357   Leonie Gerken Schofield  1998-02-15    Chelmsford   \n",
       "144662      148358  Makayla Gerken Schofield  1999-06-04    Chelmsford   \n",
       "144663      148359              Ollie Davies  1997-05-15     Guildford   \n",
       "144664      148360           William Feneley  1999-07-13       Norwich   \n",
       "144666      148362             Natasha McKay  1995-01-14        Dundee   \n",
       "144667      148363              Lewis Gibson  1994-05-01     Prestwick   \n",
       "144668      148364             Katie Ormerod  1997-08-25      Bradford   \n",
       "144669      148365           Huw Nightingale  2001-11-12        Bolton   \n",
       "144670      148366            Brogan Crowley  1994-07-20   Saddleworth   \n",
       "144671      148367               Matt Weston  1997-03-02       Redhill   \n",
       "144672      148368              Marcus Wyatt  1991-12-14       Honiton   \n",
       "144673      148369             Ellia Smeding  1998-03-16     Aylesbury   \n",
       "144675      148371              Niall Treacy  2000-07-22      Solihull   \n",
       "144760      148461              Elsa Desmond  1997-08-06  High Wycombe   \n",
       "144811      148512        Benjamin Alexander  1983-05-08        London   \n",
       "144815      148517             Ashley Watson  1993-10-28  Peterborough   \n",
       "145005      148716           Peder Kongshaug  2001-08-13     Wimbledon   \n",
       "145319      149041                Axel Brown  1992-04-02     Harrogate   \n",
       "145388      149111            Jean-Luc Baker  1993-10-07       Burnley   \n",
       "\n",
       "       born_region born_country                  NOC  height_cm  weight_kg  \\\n",
       "144659    Scotland          GBR        Great Britain        NaN        NaN   \n",
       "144661     England          GBR        Great Britain        NaN        NaN   \n",
       "144662     England          GBR        Great Britain        NaN        NaN   \n",
       "144663     England          GBR        Great Britain        NaN        NaN   \n",
       "144664     England          GBR        Great Britain        NaN        NaN   \n",
       "144666    Scotland          GBR        Great Britain        NaN        NaN   \n",
       "144667    Scotland          GBR        Great Britain        NaN        NaN   \n",
       "144668     England          GBR        Great Britain        NaN        NaN   \n",
       "144669     England          GBR        Great Britain        NaN        NaN   \n",
       "144670     England          GBR        Great Britain        NaN        NaN   \n",
       "144671     England          GBR        Great Britain        NaN        NaN   \n",
       "144672     England          GBR        Great Britain        NaN        NaN   \n",
       "144673     England          GBR        Great Britain        NaN        NaN   \n",
       "144675     England          GBR        Great Britain        NaN        NaN   \n",
       "144760     England          GBR              Ireland        NaN        NaN   \n",
       "144811     England          GBR              Jamaica        NaN        NaN   \n",
       "144815     England          GBR              Jamaica        NaN        NaN   \n",
       "145005     England          GBR               Norway      184.0       86.0   \n",
       "145319     England          GBR  Trinidad and Tobago        NaN        NaN   \n",
       "145388     England          GBR        United States        NaN        NaN   \n",
       "\n",
       "       died_date first_name born_year_str born_datetime  born_year_datetime  \\\n",
       "144659       NaN      Bruce          1994    1994-08-27              1994.0   \n",
       "144661       NaN     Leonie          1998    1998-02-15              1998.0   \n",
       "144662       NaN    Makayla          1999    1999-06-04              1999.0   \n",
       "144663       NaN      Ollie          1997    1997-05-15              1997.0   \n",
       "144664       NaN    William          1999    1999-07-13              1999.0   \n",
       "144666       NaN    Natasha          1995    1995-01-14              1995.0   \n",
       "144667       NaN      Lewis          1994    1994-05-01              1994.0   \n",
       "144668       NaN      Katie          1997    1997-08-25              1997.0   \n",
       "144669       NaN        Huw          2001    2001-11-12              2001.0   \n",
       "144670       NaN     Brogan          1994    1994-07-20              1994.0   \n",
       "144671       NaN       Matt          1997    1997-03-02              1997.0   \n",
       "144672       NaN     Marcus          1991    1991-12-14              1991.0   \n",
       "144673       NaN      Ellia          1998    1998-03-16              1998.0   \n",
       "144675       NaN      Niall          2000    2000-07-22              2000.0   \n",
       "144760       NaN       Elsa          1997    1997-08-06              1997.0   \n",
       "144811       NaN   Benjamin          1983    1983-05-08              1983.0   \n",
       "144815       NaN     Ashley          1993    1993-10-28              1993.0   \n",
       "145005       NaN      Peder          2001    2001-08-13              2001.0   \n",
       "145319       NaN       Axel          1992    1992-04-02              1992.0   \n",
       "145388       NaN   Jean-Luc          1993    1993-10-07              1993.0   \n",
       "\n",
       "       born_year_datetime_str height_category weight_category  \n",
       "144659                 1994.0          shorty     heavyweight  \n",
       "144661                 1998.0          shorty     heavyweight  \n",
       "144662                 1999.0          shorty     heavyweight  \n",
       "144663                 1997.0          shorty     heavyweight  \n",
       "144664                 1999.0          shorty     heavyweight  \n",
       "144666                 1995.0          shorty     heavyweight  \n",
       "144667                 1994.0          shorty     heavyweight  \n",
       "144668                 1997.0          shorty     heavyweight  \n",
       "144669                 2001.0          shorty     heavyweight  \n",
       "144670                 1994.0          shorty     heavyweight  \n",
       "144671                 1997.0          shorty     heavyweight  \n",
       "144672                 1991.0          shorty     heavyweight  \n",
       "144673                 1998.0          shorty     heavyweight  \n",
       "144675                 2000.0          shorty     heavyweight  \n",
       "144760                 1997.0          shorty     heavyweight  \n",
       "144811                 1983.0          shorty     heavyweight  \n",
       "144815                 1993.0          shorty     heavyweight  \n",
       "145005                 2001.0            tall    middleweight  \n",
       "145319                 1992.0          shorty     heavyweight  \n",
       "145388                 1993.0          shorty     heavyweight  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merge and Concatenate Data\n",
    "# Let's convert country abr to full country\n",
    "# Load the metadata file\n",
    "nocs_df = pd.read_csv('./data/noc_regions.csv')\n",
    "\n",
    "# nocs_df.head(20)\n",
    "bios_new.head()\n",
    "bios_new2 = bios_new.merge(nocs_df, how='left', right_on='NOC', left_on='born_country')\n",
    "bios_new2.rename(columns={'region':'born_country_full'}, inplace=True)\n",
    "nanPts = pd.isna(bios_new2['born_country_full'])\n",
    "country_pts = bios_new2['NOC_x'] != bios_new2['born_country_full']\n",
    "# npIdx = np.where(nanPts & country_pts) # you can also do this to get index instead of boolean array \n",
    "outsiders_df = bios_new2[(bios_new2['NOC_x'] != bios_new2['born_country_full']) & ~pd.isna(bios_new2['born_country_full'])]\n",
    "outsiders_df.head()\n",
    "\n",
    "fra_df = bios_new[bios_new['born_country'] == \"FRA\"]\n",
    "grb_df = bios_new[bios_new['born_country'] == \"GBR\"]\n",
    "comb_df = pd.concat([fra_df, grb_df])\n",
    "comb_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "7b448f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>revenue</th>\n",
       "      <th>price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Units Sold Interpolate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>25.0</td>\n",
       "      <td>99.75</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>35.0</td>\n",
       "      <td>139.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>25.0</td>\n",
       "      <td>149.75</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>40.0</td>\n",
       "      <td>159.60</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>30.0</td>\n",
       "      <td>179.70</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Day Coffee Type  Units Sold  revenue  price  Price  \\\n",
       "0      Monday    Espresso        25.0    99.75   4.99   3.99   \n",
       "3     Tuesday       Latte        20.0   119.80   4.99   5.99   \n",
       "4   Wednesday    Espresso        35.0   139.65   4.99   3.99   \n",
       "5   Wednesday       Latte        25.0   149.75   4.99   5.99   \n",
       "6    Thursday    Espresso        40.0   159.60   4.99   3.99   \n",
       "7    Thursday       Latte        30.0   179.70   4.99   5.99   \n",
       "8      Friday    Espresso        45.0   179.55   4.99   3.99   \n",
       "9      Friday       Latte        35.0   209.65   4.99   5.99   \n",
       "10   Saturday    Espresso        45.0   179.55   4.99   3.99   \n",
       "11   Saturday       Latte        35.0   209.65   4.99   5.99   \n",
       "12     Sunday    Espresso        45.0   179.55   4.99   3.99   \n",
       "13     Sunday       Latte        35.0   209.65   4.99   5.99   \n",
       "\n",
       "    Units Sold Interpolate  \n",
       "0                     25.0  \n",
       "3                     20.0  \n",
       "4                     35.0  \n",
       "5                     25.0  \n",
       "6                     40.0  \n",
       "7                     30.0  \n",
       "8                     45.0  \n",
       "9                     35.0  \n",
       "10                    45.0  \n",
       "11                    35.0  \n",
       "12                    45.0  \n",
       "13                    35.0  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Interpolate\n",
    "coffee_new = coffee.copy()\n",
    "coffee_new.loc[1:2,'Units Sold'] = np.nan\n",
    "coffee_new['Units Sold Interpolate'] = coffee_new['Units Sold'].interpolate().round(1)\n",
    "coffee_new2 = coffee_new.dropna(subset=['Units Sold'])\n",
    "coffee_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "16d2376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Espresso</th>\n",
       "      <th>Latte</th>\n",
       "      <th>Espresso</th>\n",
       "      <th>Latte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>179.55</td>\n",
       "      <td>209.65</td>\n",
       "      <td>179.55</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>99.75</td>\n",
       "      <td>89.85</td>\n",
       "      <td>99.75</td>\n",
       "      <td>89.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>179.55</td>\n",
       "      <td>209.65</td>\n",
       "      <td>179.55</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>179.55</td>\n",
       "      <td>209.65</td>\n",
       "      <td>179.55</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>159.60</td>\n",
       "      <td>179.70</td>\n",
       "      <td>159.60</td>\n",
       "      <td>179.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>119.70</td>\n",
       "      <td>119.80</td>\n",
       "      <td>119.70</td>\n",
       "      <td>119.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>139.65</td>\n",
       "      <td>149.75</td>\n",
       "      <td>139.65</td>\n",
       "      <td>149.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sum             mean        \n",
       "Coffee Type Espresso   Latte Espresso   Latte\n",
       "Day                                          \n",
       "Friday        179.55  209.65   179.55  209.65\n",
       "Monday         99.75   89.85    99.75   89.85\n",
       "Saturday      179.55  209.65   179.55  209.65\n",
       "Sunday        179.55  209.65   179.55  209.65\n",
       "Thursday      159.60  179.70   159.60  179.70\n",
       "Tuesday       119.70  119.80   119.70  119.80\n",
       "Wednesday     139.65  149.75   139.65  149.75"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Aggregation\n",
    "o = bios_new2['born_country_full'].value_counts()\n",
    "meanCountryCount = o.mean\n",
    "med = o.median()\n",
    "\n",
    "coffee.groupby(['Coffee Type']).agg({'Units Sold':'mean', 'Price': 'median'})\n",
    "\n",
    "# Pivot Tables\n",
    "pivot = coffee.pivot_table(columns=['Coffee Type'], index='Day', values='revenue',aggfunc=['sum','mean'])\n",
    "pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "69961b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Coffee Type</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>revenue</th>\n",
       "      <th>price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Units Sold Interpolate</th>\n",
       "      <th>yesterday_revenue</th>\n",
       "      <th>percentChang</th>\n",
       "      <th>revenue_rank</th>\n",
       "      <th>CumulativeRevenue</th>\n",
       "      <th>CumulativeMaxRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>25.0</td>\n",
       "      <td>99.75</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.55</td>\n",
       "      <td>119.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>35.0</td>\n",
       "      <td>139.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>35.0</td>\n",
       "      <td>99.75</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>359.20</td>\n",
       "      <td>139.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>25.0</td>\n",
       "      <td>149.75</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>25.0</td>\n",
       "      <td>119.80</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>508.95</td>\n",
       "      <td>149.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>40.0</td>\n",
       "      <td>159.60</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>40.0</td>\n",
       "      <td>139.65</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>668.55</td>\n",
       "      <td>159.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>30.0</td>\n",
       "      <td>179.70</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.75</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>848.25</td>\n",
       "      <td>179.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>45.0</td>\n",
       "      <td>159.60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1027.80</td>\n",
       "      <td>179.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.0</td>\n",
       "      <td>179.70</td>\n",
       "      <td>16.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1237.45</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1417.00</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1626.65</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>45.0</td>\n",
       "      <td>179.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1806.20</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Latte</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.0</td>\n",
       "      <td>209.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2015.85</td>\n",
       "      <td>209.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeRevenue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeMaxRevenue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Day Coffee Type  Units Sold  revenue  price  \\\n",
       "0                        Monday    Espresso        25.0    99.75   4.99   \n",
       "3                       Tuesday       Latte        20.0   119.80   4.99   \n",
       "4                     Wednesday    Espresso        35.0   139.65   4.99   \n",
       "5                     Wednesday       Latte        25.0   149.75   4.99   \n",
       "6                      Thursday    Espresso        40.0   159.60   4.99   \n",
       "7                      Thursday       Latte        30.0   179.70   4.99   \n",
       "8                        Friday    Espresso        45.0   179.55   4.99   \n",
       "9                        Friday       Latte        35.0   209.65   4.99   \n",
       "10                     Saturday    Espresso        45.0   179.55   4.99   \n",
       "11                     Saturday       Latte        35.0   209.65   4.99   \n",
       "12                       Sunday    Espresso        45.0   179.55   4.99   \n",
       "13                       Sunday       Latte        35.0   209.65   4.99   \n",
       "CumulativeRevenue           NaN         NaN         NaN      NaN    NaN   \n",
       "CumulativeMaxRevenue        NaN         NaN         NaN      NaN    NaN   \n",
       "\n",
       "                      Price  Units Sold Interpolate  yesterday_revenue  \\\n",
       "0                      3.99                    25.0                NaN   \n",
       "3                      5.99                    20.0                NaN   \n",
       "4                      3.99                    35.0              99.75   \n",
       "5                      5.99                    25.0             119.80   \n",
       "6                      3.99                    40.0             139.65   \n",
       "7                      5.99                    30.0             149.75   \n",
       "8                      3.99                    45.0             159.60   \n",
       "9                      5.99                    35.0             179.70   \n",
       "10                     3.99                    45.0             179.55   \n",
       "11                     5.99                    35.0             209.65   \n",
       "12                     3.99                    45.0             179.55   \n",
       "13                     5.99                    35.0             209.65   \n",
       "CumulativeRevenue       NaN                     NaN             179.55   \n",
       "CumulativeMaxRevenue    NaN                     NaN             209.65   \n",
       "\n",
       "                      percentChang  revenue_rank  CumulativeRevenue  \\\n",
       "0                              NaN           1.0              99.75   \n",
       "3                              NaN           2.0             219.55   \n",
       "4                             40.0           3.0             359.20   \n",
       "5                             25.0           4.0             508.95   \n",
       "6                             14.3           5.0             668.55   \n",
       "7                             20.0           9.0             848.25   \n",
       "8                             12.5           7.0            1027.80   \n",
       "9                             16.7          11.0            1237.45   \n",
       "10                             0.0           7.0            1417.00   \n",
       "11                             0.0          11.0            1626.65   \n",
       "12                             0.0           7.0            1806.20   \n",
       "13                             0.0          11.0            2015.85   \n",
       "CumulativeRevenue              NaN           NaN                NaN   \n",
       "CumulativeMaxRevenue           NaN           NaN                NaN   \n",
       "\n",
       "                      CumulativeMaxRevenue  \n",
       "0                                    99.75  \n",
       "3                                   119.80  \n",
       "4                                   139.65  \n",
       "5                                   149.75  \n",
       "6                                   159.60  \n",
       "7                                   179.70  \n",
       "8                                   179.70  \n",
       "9                                   209.65  \n",
       "10                                  209.65  \n",
       "11                                  209.65  \n",
       "12                                  209.65  \n",
       "13                                  209.65  \n",
       "CumulativeRevenue                      NaN  \n",
       "CumulativeMaxRevenue                   NaN  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Advanced Functions\n",
    "coffee_new2.loc[:,'yesterday_revenue'] = coffee_new2['revenue'].shift(2) # Moves the values by 2 rows (nan pad)\n",
    "coffee_new2.loc[:,'percentChang'] = (coffee_new2['revenue'] / coffee_new2['yesterday_revenue'] * 100 - 100).round(1)\n",
    "\n",
    "coffee_new2.loc[:,'revenue_rank'] = coffee_new2['revenue'].rank() # Rank == 1 is least revenue, rank == end == most revenue\n",
    "# coffee_new2.sort_values('revenue_rank')\n",
    "\n",
    "coffee_new2.loc[:,'CumulativeRevenue'] = coffee_new2['revenue'].cumsum()\n",
    "coffee_new2.loc[:,'CumulativeMaxRevenue'] = coffee_new2['revenue'].cummax()\n",
    "coffee_new2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
